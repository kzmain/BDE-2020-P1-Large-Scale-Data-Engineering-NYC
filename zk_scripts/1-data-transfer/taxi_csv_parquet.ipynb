{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import TimestampType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Set up modes and dirs\n",
    "overwrite  = False\n",
    "databricks = False\n",
    "if not databricks:\n",
    "    from util import folder\n",
    "    data_dir = folder.DATA_DIR\n",
    "    from_dir = folder.YELL_DIR\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "else:\n",
    "    data_dir = \"/dbfs/mnt/group01\"\n",
    "    from_dir = \"/dbfs/mnt/nyc-tlc/trip data\"\n",
    "\n",
    "to_file = to_dbfs = data_dir + \"/yellow/raw/{}/{}.gz.parquet\"\n",
    "fr_file = fr_dbfs = from_dir + \"/yellow_tripdata_{}-{}.csv\"\n",
    "\n",
    "if databricks:\n",
    "    to_dbfs = to_dbfs.replace(\"/dbfs\", \"\")\n",
    "    fr_dbfs = fr_dbfs.replace(\"/dbfs\", \"\")\n",
    "dirs = [data_dir]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for d in dirs:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "year_start = 2009\n",
    "year_end   = 2016\n",
    "year_range = range(year_start, year_end + 1)\n",
    "\n",
    "month_range = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\",\n",
    "               \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def check_file_exist(_path):\n",
    "    if os.path.exists(_path) and not overwrite:\n",
    "            print(\"[SYSTEM]: File exists: {}\".format(_path))\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def update_columns(_in_df):\n",
    "    _old_columns = _in_df.columns\n",
    "    _new_columns = [_col.lower()\n",
    "               .strip()\n",
    "               .replace(\"vendor_name\", \"vendor_id\")\n",
    "               .replace(\"vendorid\", \"vendor_id\")\n",
    "               .replace(\"start_lon\", \"pickup_longitude\")\n",
    "               .replace(\"start_lat\", \"pickup_latitude\")\n",
    "               .replace(\"end_lon\", \"dropoff_longitude\")\n",
    "               .replace(\"end_lat\", \"dropoff_latitude\")\n",
    "               .replace(\"amt\", \"amount\")\n",
    "               .replace(\"trip_pickup_datetime\" , \"pickup_datetime\")\n",
    "               .replace(\"trip_dropoff_datetime\", \"dropoff_datetime\")\n",
    "               .replace(\"fwd_flag\", \"forward\")\n",
    "               .replace(\"tpep_\", \"\")\n",
    "               .replace(\"ratecodeid\", \"rate_code\")\n",
    "               .replace(\"improvement_\", \"\")\n",
    "           for _col in _old_columns]\n",
    "    for _cnt in range(0, len(_old_columns)):\n",
    "        _in_df = _in_df.withColumnRenamed(_old_columns[_cnt], _new_columns[_cnt])\n",
    "        if \"date\" in _new_columns[_cnt]:\n",
    "            _in_df = _in_df.withColumn(_new_columns[_cnt], col(_new_columns[_cnt]).cast(TimestampType()))\n",
    "        else:\n",
    "            _in_df = _in_df.withColumn(_new_columns[_cnt], col(_new_columns[_cnt]).cast(DoubleType()))\n",
    "    return _in_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def select_columns(_in_df):\n",
    "    return _in_df.select([\"pickup_datetime\", \"dropoff_datetime\",\n",
    "                 \"dropoff_latitude\", \"dropoff_longitude\",\n",
    "                 \"pickup_latitude\", \"pickup_longitude\",\n",
    "                \"trip_distance\", \"tip_amount\", \"total_amount\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def csv_parquet():\n",
    "    info_title = lambda _y, _m: print(\"____________________________YELLOW_{}_{}____________________________\".format(_y, _m))\n",
    "    info_start = lambda _y, _m: print(\"[SYSTEM]: Start  {}-{}\".format(_y, _m))\n",
    "    info_end   = lambda _y, _m: print(\"[SYSTEM]: Finish {}-{}\".format(_y, _m))\n",
    "\n",
    "    for _year in year_range:\n",
    "        for _month in month_range:\n",
    "            if _year == 2016 and int(_month) > 6:\n",
    "                break\n",
    "            _dest = to_dbfs.format(_year, int(_month))\n",
    "            _from = fr_dbfs.format(_year, _month)\n",
    "            _file = to_file.format(_year, int(_month))\n",
    "            if not os.path.exists(fr_file.format(_year, _month)):\n",
    "                continue\n",
    "            info_title(_year, _month)\n",
    "            if check_file_exist(_file):\n",
    "                continue\n",
    "            info_start(_year, _month)\n",
    "            _df = spark.read.option(\"header\", True).csv(_from)\n",
    "            _df = update_columns(_df)\n",
    "            # _df = select_columns(_df)\n",
    "            _df.write.mode(\"overwrite\")\\\n",
    "                .option(\"compression\", \"gzip\")\\\n",
    "                .parquet(_dest)\n",
    "            info_end(_year, _month)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________YELLOW_2009_01____________________________\n",
      "[SYSTEM]: Start  2009-01\n",
      "[SYSTEM]: Finish 2009-01\n",
      "____________________________YELLOW_2009_02____________________________\n",
      "[SYSTEM]: Start  2009-02\n",
      "[SYSTEM]: Finish 2009-02\n",
      "____________________________YELLOW_2009_03____________________________\n",
      "[SYSTEM]: Start  2009-03\n",
      "[SYSTEM]: Finish 2009-03\n",
      "____________________________YELLOW_2009_04____________________________\n",
      "[SYSTEM]: Start  2009-04\n",
      "[SYSTEM]: Finish 2009-04\n",
      "____________________________YELLOW_2009_05____________________________\n",
      "[SYSTEM]: Start  2009-05\n",
      "[SYSTEM]: Finish 2009-05\n",
      "____________________________YELLOW_2011_07____________________________\n",
      "[SYSTEM]: Start  2011-07\n",
      "[SYSTEM]: Finish 2011-07\n",
      "____________________________YELLOW_2011_08____________________________\n",
      "[SYSTEM]: Start  2011-08\n",
      "[SYSTEM]: Finish 2011-08\n",
      "____________________________YELLOW_2011_09____________________________\n",
      "[SYSTEM]: Start  2011-09\n",
      "[SYSTEM]: Finish 2011-09\n",
      "____________________________YELLOW_2011_10____________________________\n",
      "[SYSTEM]: Start  2011-10\n",
      "[SYSTEM]: Finish 2011-10\n"
     ]
    }
   ],
   "source": [
    "csv_parquet()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# df = spark.read.option(\"header\", True).csv(\"/Users/kzmain/LSDE/data/yellow_download/yellow_tripdata_2009-01.csv\")\n",
    "# df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# root-foil\n",
    "#  |-- medallion: integer (nullable = true)\n",
    "#  |-- hack_license: integer (nullable = true)\n",
    "#  |-- pickup_datetime: timestamp (nullable = true)\n",
    "#  |-- dropoff_latitude: double (nullable = true)\n",
    "#  |-- dropoff_longitude: double (nullable = true)\n",
    "#  |-- pickup_latitude: double (nullable = true)\n",
    "#  |-- pickup_longitude: double (nullable = true)\n",
    "#  |-- trip_distance: double (nullable = true)\n",
    "#  |-- trip_time_in_secs: integer (nullable = true)\n",
    "#  |-- dropoff_datetime: timestamp (nullable = true)\n",
    "#  |-- rate_code: short (nullable = true)\n",
    "#  |-- tip_amount: double (nullable = true)\n",
    "#  |-- total_amount: double (nullable = true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}