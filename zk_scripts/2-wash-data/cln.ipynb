{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import osmnx as ox\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as func"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up modes and dirs\n",
    "databricks = False\n",
    "overwrite = False\n",
    "is_yellow = False\n",
    "yellow = \"yellow\" if is_yellow else \"foil\"\n",
    "pick_up = \"pickup\"\n",
    "drop_off = \"dropoff\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not databricks:\n",
    "    data_dir = \"/Users/kzmain/LSDE/data\"\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "else:\n",
    "    data_dir = \"/dbfs/mnt/group01\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_dir = data_dir + \"/temp\"\n",
    "temp_zone_path = temp_zone_dbfs = data_dir + \"/temp/{}.{}.zone.gz.parquet\"\n",
    "temp_edge_path = temp_edge_dbfs = data_dir + \"/temp/{}.{}.edge.gz.parquet\"\n",
    "temp_data_path = temp_data_dbfs = data_dir + \"/temp/{}.data.gz.parquet\"\n",
    "\n",
    "fr_file = fr_dbfs = (data_dir + \"/{}\".format(yellow) + \"/raw/{}/{}.gz.parquet\")\n",
    "to_file = to_dbfs = (data_dir + \"/{}\".format(yellow) + \"/cln/{}/{}.gz.parquet\")\n",
    "\n",
    "if databricks:\n",
    "    fr_dbfs = fr_dbfs.replace(\"/dbfs\", \"\")\n",
    "    to_dbfs = to_dbfs.replace(\"/dbfs\", \"\")\n",
    "    temp_zone_dbfs = temp_zone_dbfs.replace(\"/dbfs\", \"\")\n",
    "    temp_edge_dbfs = temp_edge_dbfs.replace(\"/dbfs\", \"\")\n",
    "    temp_data_dbfs = temp_data_dbfs.replace(\"/dbfs\", \"\")\n",
    "\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if is_yellow:\n",
    "    start_year = 2009\n",
    "    end_year = 2016\n",
    "else:\n",
    "    start_year = 2010\n",
    "    end_year = 2013"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "year_range = range(start_year, end_year + 1)\n",
    "month_range = range(1, 13)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_file_exist(_path):\n",
    "    if os.path.exists(_path) and not overwrite:\n",
    "        print(\"[SYSTEM]: File exists: {}\".format(_path))\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_lon = -74.2463  # left bound\n",
    "e_lon = -73.7141  # right bound\n",
    "n_lat = 40.9166  # up bound\n",
    "s_lat = 40.4767  # down bound\n",
    "\n",
    "drop_lon = \"dropoff_longitude\"\n",
    "drop_lat = \"dropoff_latitude\"\n",
    "pick_lon = \"pickup_longitude\"\n",
    "pick_lat = \"pickup_latitude\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Data comes from osmnx map\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shp_path = os.path.join(data_dir, \"nyc/zone\")\n",
    "map_path = os.path.join(data_dir, \"nyc/map/NYC.mph\")\n",
    "\n",
    "nyc_shp = gpd.read_file(shp_path)\n",
    "nyc_shp = nyc_shp.to_crs(epsg=4326)\n",
    "nyc_map = ox.load_graphml(map_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_file_list(_path):\n",
    "    _parquet_file_list = []\n",
    "    for _root, _dirs, _files in os.walk(_path, topdown=False):\n",
    "        for _name in _files:\n",
    "            _file_name = os.path.join(_root, _name)\n",
    "            if Path(_file_name).suffix == '.parquet':\n",
    "                _parquet_file_list.append(_file_name)\n",
    "    return _parquet_file_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_from_parquet(_file_list):\n",
    "    _full_df = pandas.concat(pandas.read_parquet(_parquet_file) for _parquet_file in _file_list)\n",
    "    _full_df = filter_location(_full_df)\n",
    "    _full_df = filter_duration(_full_df)\n",
    "    _full_df = filter_distance(_full_df)\n",
    "    # print(_full_df.shape) (14863778, 16)\n",
    "    _full_df = _full_df[_full_df['valid']]\n",
    "    # print(_full_df.shape) (14507105, 16)\n",
    "    _full_df.to_parquet(temp_data_path.format(yellow), compression='gzip', index=False)\n",
    "\n",
    "    _pick_df = _full_df[[pick_lon, pick_lat]].drop_duplicates()\n",
    "    _drop_df = _full_df[[drop_lon, drop_lat]].drop_duplicates()\n",
    "    return _pick_df, _drop_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_location(_in_df):\n",
    "    _in_df = _in_df.round({drop_lat: 4, drop_lon: 4, pick_lat: 4, pick_lon: 4})\n",
    "    _in_df['valid'] = True\n",
    "    _in_df.loc[_in_df[pick_lon] > e_lon, 'valid'] = False\n",
    "    _in_df.loc[_in_df[pick_lon] < w_lon, 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lon] > e_lon, 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lon] < w_lon, 'valid'] = False\n",
    "    _in_df.loc[_in_df[pick_lat] > n_lat, 'valid'] = False\n",
    "    _in_df.loc[_in_df[pick_lat] < s_lat, 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lat] > n_lat, 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lat] < s_lat, 'valid'] = False\n",
    "\n",
    "    _in_df.loc[_in_df[pick_lon].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[pick_lon].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lon].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lon].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[pick_lat].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[pick_lat].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lat].isnull(), 'valid'] = False\n",
    "    _in_df.loc[_in_df[drop_lat].isnull(), 'valid'] = False\n",
    "    return _in_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_duration(_in_df):\n",
    "    duration_delta = \"duration\"\n",
    "    duration_secod = \"duration_second\"\n",
    "    _in_df[duration_delta] = _in_df[\"dropoff_datetime\"] - _in_df[\"pickup_datetime\"]\n",
    "    _in_df[duration_secod] = _in_df[duration_delta] / np.timedelta64(1, 's')\n",
    "    _in_df.loc[_in_df[duration_secod] < 45, 'valid'] = False\n",
    "    return _in_df.drop(columns='duration')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_distance(_in_df):\n",
    "    _in_df.loc[_in_df[\"trip_distance\"] < 0.45, 'valid'] = False\n",
    "    return _in_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_taxi_zones(_in_df, mode):\n",
    "    # Change pandas data frame to geo_pandas data frame\n",
    "    _lon = \"{}_longitude\".format(mode)\n",
    "    _lat = \"{}_latitude\".format(mode)\n",
    "\n",
    "    _geo_df = gpd.GeoDataFrame(_in_df, geometry=gpd.points_from_xy(_in_df[_lon], _in_df[_lat]))\n",
    "\n",
    "    # Get zone location\n",
    "    _geo_df = gpd.sjoin(_geo_df, nyc_shp, how=\"inner\", op=\"intersects\")\n",
    "    # Change geo_pandas data frame to pandas data frame\n",
    "    _geo_df = pandas \\\n",
    "        .DataFrame(_geo_df.drop(columns='geometry'))[[_lon, _lat, \"LocationID\"]] \\\n",
    "        .rename(columns={\"LocationID\": \"{}_zone_id\".format(mode)})\n",
    "    _geo_df.to_parquet(temp_zone_path.format(yellow, mode), compression='gzip', index=False)\n",
    "    return _geo_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_taxi_edges(_in_df, mode):\n",
    "    _lons = _in_df[\"{}_longitude\".format(mode)]\n",
    "    _lats = _in_df[\"{}_latitude\".format(mode)]\n",
    "    _result = ox.get_nearest_edges(nyc_map, _lons, _lats, method=\"kdtree\")\n",
    "    _u = []\n",
    "    _v = []\n",
    "    for _r in _result:\n",
    "        _u.append(int(_r[0]))\n",
    "        _v.append(int(_r[1]))\n",
    "\n",
    "    _in_df[\"{}_u\".format(mode)] = _u\n",
    "    _in_df[\"{}_v\".format(mode)] = _v\n",
    "    _in_df = _in_df.drop(columns='geometry')\n",
    "    _in_df.to_parquet(temp_edge_path.format(yellow, mode), compression='gzip', index=False)\n",
    "    return _in_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def expand_time(_in_df):\n",
    "    return _in_df \\\n",
    "        .withColumn(\"drop_min\", func.minute(\"dropoff_datetime\")) \\\n",
    "        .withColumn(\"drop_hour\", func.hour(\"dropoff_datetime\")) \\\n",
    "        .withColumn(\"drop_day\", func.dayofmonth(\"dropoff_datetime\")) \\\n",
    "        .withColumn(\"drop_month\", func.month(\"dropoff_datetime\")) \\\n",
    "        .withColumn(\"drop_year\", func.year(\"dropoff_datetime\")) \\\n",
    "        .withColumn(\"pick_min\", func.minute(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"pick_hour\", func.hour(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"pick_day\", func.dayofmonth(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"pick_month\", func.month(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"pick_year\", func.year(\"pickup_datetime\")) \\\n",
    "        .withColumn(\"week_day\", func.dayofweek(\"pickup_datetime\")) \\\n",
    "        #%%\n",
    "\n",
    "\n",
    "# https://www.timeanddate.com/calendar/seasons.html?n=900\n",
    "def expand_season(_df, _m):\n",
    "    if 6 >= _m >= 4:\n",
    "        _df = _df.withColumn(\"season\", func.lit(1))\n",
    "    if 9 >= _m >= 7:\n",
    "        _df = _df.withColumn(\"season\", func.lit(2))\n",
    "    elif 12 >= _m >= 10:\n",
    "        _df = _df.withColumn(\"season\", func.lit(3))\n",
    "    elif 3 >= _m >= 1:\n",
    "        _df = _df.withColumn(\"season\", func.lit(4))\n",
    "    return _df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def select_columns(_in_df):\n",
    "    if not is_yellow:\n",
    "        _in_df = _in_df.drop(\"trip_time_in_secs\")\n",
    "    else:\n",
    "        for c in _in_df.columns:\n",
    "            if c in [\"vendor_id\", \"passenger_count\", \"store_and_forward\", \"payment_type\",\n",
    "                     \"fare_amount\", \"surcharge\", \"mta_tax\", \"tolls_amount\"]:\n",
    "                _in_df = _in_df.drop(c)\n",
    "    return _in_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process():\n",
    "    info_strin = \"____________________________{}_PROCESS_{}_{}____________________________\"\n",
    "    info_title = lambda _mode, _y, _m: print(info_strin.format(_mode.upper(), _y, _m))\n",
    "    info_start = lambda _y, _m: print(\"[SYSTEM]: Start  {}-{}\".format(_y, _m))\n",
    "    info_end = lambda _y, _m: print(\"[SYSTEM]: Finish {}-{}\".format(_y, _m))\n",
    "    for year in year_range:\n",
    "        for month in month_range:\n",
    "            if not os.path.exists(fr_file.format(year, month)):\n",
    "                continue\n",
    "            info_title(yellow, year, month)\n",
    "            if check_file_exist(to_file.format(year, month)):\n",
    "                continue\n",
    "            info_start(year, month)\n",
    "            from datetime import datetime\n",
    "            s = datetime.now()\n",
    "            # Get file location of the parquet\n",
    "            raw_file_path = fr_file.format(year, month)\n",
    "            raw_file_dbfs = fr_dbfs.format(year, month)\n",
    "\n",
    "            # Read in parquet file by year-month\n",
    "            parquet_file_list = get_file_list(raw_file_path)\n",
    "            pick_df, drop_df = read_from_parquet(parquet_file_list)\n",
    "\n",
    "            # # Fetch taxi zones\n",
    "            print(\"[SYSTEM]: GET TAXI ZONE\")\n",
    "            get_taxi_zones(pick_df, pick_up)\n",
    "            get_taxi_zones(drop_df, drop_off)\n",
    "            pick_zone = spark.read.parquet(temp_zone_dbfs.format(yellow, pick_up))\n",
    "            drop_zone = spark.read.parquet(temp_zone_dbfs.format(yellow, drop_off))\n",
    "\n",
    "            # Get taxi edges\n",
    "            print(\"[SYSTEM]: GET TAXI EDGE\")\n",
    "            get_taxi_edges(pick_df, pick_up)\n",
    "            get_taxi_edges(drop_df, drop_off)\n",
    "            pick_edge = spark.read.parquet(temp_edge_dbfs.format(yellow, pick_up))\n",
    "            # drop_edge = spark.read.parquet(temp_edge_dbfs.format(yellow, drop_off))\n",
    "\n",
    "            print(\"[SYSTEM]: GET FULL DF\")\n",
    "            origin_df = spark.read.parquet(temp_data_dbfs.format(yellow))\n",
    "\n",
    "            finl_df = select_columns(origin_df)\n",
    "\n",
    "            print(\"[SYSTEM]: JOIN\")\n",
    "            finl_df = finl_df \\\n",
    "                .join(pick_zone, [pick_lon, pick_lat], how=\"left_outer\") \\\n",
    "                .join(pick_edge, [pick_lon, pick_lat], how=\"left_outer\") \\\n",
    "                .join(drop_zone, [drop_lon, drop_lat], how=\"left_outer\") \\\n",
    "                # .join(drop_edge, [drop_lon, drop_lat], how=\"left_outer\")\n",
    "\n",
    "            print(\"[SYSTEM]: FEATURE\")\n",
    "            finl_df = expand_time(finl_df)\n",
    "            finl_df = expand_season(finl_df, month)\n",
    "\n",
    "            finl_df.repartition(\"pick_day\", \"pick_hour\") \\\n",
    "                .write.mode(\"overwrite\") \\\n",
    "                .option(\"compression\", \"gzip\") \\\n",
    "                .partitionBy(\"pick_day\", \"pick_hour\") \\\n",
    "                .parquet(to_dbfs.format(year, month))\n",
    "            info_end(year, month)\n",
    "            print(\"spent {}\".format(datetime.now() - s))\n",
    "\n",
    "\n",
    "process()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}