{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set up modes and dirs\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "overwrite = True\n",
    "databricks = False\n",
    "is_yellow = False\n",
    "\n",
    "yellow = \"yellow\" if is_yellow else \"foil\"\n",
    "pick_up = \"pickup\"\n",
    "drop_off = \"dropoff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not databricks:\n",
    "    data_dir = \"/Users/kzmain/LSDE/data\"\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "else:\n",
    "    data_dir = \"/dbfs/mnt/group01\"\n",
    "clean_file  = clean_dbfs  = (data_dir + \"/{}\".format(yellow) + \"/cln/{}/{}.gz.parquet\")\n",
    "result_file = result_dbfs = (data_dir + \"/{}\".format(yellow) + \"/feature/{}/{}.gz.parquet\")\n",
    "\n",
    "if databricks:\n",
    "    clean_dbfs = clean_dbfs.replace(\"/dbfs\", \"\")\n",
    "    result_dbfs = result_dbfs.replace(\"/dbfs\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fr_year = 2009\n",
    "fr_month = 1\n",
    "\n",
    "to_year = 2017\n",
    "to_month = 12\n",
    "\n",
    "cluster_radian = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_file_exist(_path):\n",
    "    if os.path.exists(_path) and not overwrite:\n",
    "            print(\"[SYSTEM]: File exists: {}\".format(_path))\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_cln(_year, _month):\n",
    "    return spark.read.parquet(clean_dbfs.format(_year, _month)).repartition(200, \"pick_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dur_col = \"duration_second\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_duration(_in_df):\n",
    "    _in_df = _in_df.withColumn(dur_col, when(col(dur_col) > 4 * 60 * 60, False).otherwise(col(dur_col)))\n",
    "    return _in_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_is_weekend(_in_df):\n",
    "    _in_df = _in_df.withColumn(\"is_weekend\", when(col(\"week_day\") > 5, lit(True)).otherwise(lit(False)))\n",
    "    return _in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_weather(_in, _year):\n",
    "    def get_weather():\n",
    "        # |         time_stamp|hour|day|high|low|baro|wind| wd|hum|weather|year|month|\n",
    "        weather_dbfs = (data_dir + \"/nyc/weather/parquet\").replace(\"/dbfs\", \"\")\n",
    "        return spark.read.parquet(weather_dbfs).drop(\"time_stamp\")\n",
    "\n",
    "    _wh = get_weather().filter(col(\"year\") == _year)\n",
    "    _pm = \"pick_month\"\n",
    "    _pd = \"pick_day\"\n",
    "    _ph = \"pick_hour\"\n",
    "    _m = \"month\"\n",
    "    _d = \"day\"\n",
    "    _h = \"hour\"\n",
    "    _l = \"left_outer\"\n",
    "\n",
    "    return _in.join(_wh, (_in[_pm] == _wh[_m]) & (_in[_pd] == _wh[_d]) & (_in[_ph] == _wh[_h]), how=_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "drop_stmp = \"dropoff_datetime\"\n",
    "pick_stmp = \"pickup_datetime\"\n",
    "prev_stmp = \"predrop_datetime\"\n",
    "\n",
    "trip_cruise = \"trip_cruise_second\"\n",
    "\n",
    "day_is_sleep = \"day_is_sleep_in_day\"\n",
    "day_sleep_len = \"day_sleep_second\"\n",
    "day_trip_sum = \"day_trip_count\"\n",
    "day_work_len = \"day_work_second\"\n",
    "\n",
    "mean_cruise = \"day_mean_cruise_second_per_trip\"\n",
    "mean_travel = \"day_mean_travel_second_per_trip\"\n",
    "mean_tip = \"day_mean_tip_per_trip\"\n",
    "\n",
    "month_income = \"month_income_total\"\n",
    "month_work_len = \"month_work_hour\"\n",
    "month_income_mean = \"month_income_per_hour\"\n",
    "month_weekend = \"month_work_on_weekend\"\n",
    "# if is foil\n",
    "_w1 = Window.partitionBy(\"medallion\", \"hack_license\", \"pick_month\", \"pick_day\").orderBy(pick_stmp)\n",
    "_w2 = Window.partitionBy(\"medallion\", \"hack_license\", \"pick_month\", \"pick_day\")\n",
    "month_window = Window.partitionBy(\"medallion\", \"hack_license\", \"pick_month\")\n",
    "\n",
    "def feature_cruise_len(_in_df):\n",
    "    _in_df = _in_df.withColumn(prev_stmp, lag(_in_df[drop_stmp]).over(_w1))\n",
    "    _in_df = _in_df.withColumn(trip_cruise, unix_timestamp(col(pick_stmp)) - unix_timestamp(col(prev_stmp)))\n",
    "    _in_df = _in_df.withColumn(trip_cruise, when(col(trip_cruise) > 4 * 60 * 60, lit(None)).otherwise(col(trip_cruise)))\n",
    "    return _in_df\n",
    "\n",
    "def feature_sleep_in_day(_in_df):\n",
    "    _in_df = _in_df.withColumn(day_is_sleep, when(col(trip_cruise) > 4 * 60 * 60, True).otherwise(False))\n",
    "    _in_df = _in_df.withColumn(day_is_sleep, max(col(day_is_sleep)).over(_w2))\n",
    "    _in_df = _in_df.withColumn(day_sleep_len, when(col(trip_cruise) > 4 * 60 * 60, col(trip_cruise)).otherwise(lit(None)))\n",
    "    return _in_df\n",
    "\n",
    "def feature_trip_count(_in_df):\n",
    "    _in_df = _in_df.withColumn(day_trip_sum,  count(col(pick_stmp)).over(_w2))\n",
    "    return _in_df\n",
    "\n",
    "def feature_work_time(_in_df):\n",
    "    _srt = \"day_start_stamp\"\n",
    "    _end = \"day_end_stamp\"\n",
    "    _in_df = _in_df.withColumn(_srt, min(unix_timestamp(col(pick_stmp))).over(_w2))\n",
    "    _in_df = _in_df.withColumn(_end, max(unix_timestamp(col(drop_stmp))).over(_w2))\n",
    "    _in_df = _in_df.withColumn(day_work_len, col(_end) - col(_srt) - sum(col(_end)).over(_w2))\n",
    "    return _in_df.drop([_srt, _end])\n",
    "\n",
    "def feature_foil(_in_df):\n",
    "    # Get trip_cruise\n",
    "    _in_df = feature_cruise_len(_in_df)\n",
    "    _in_df = feature_sleep_in_day(_in_df)\n",
    "    _in_df = feature_work_time(_in_df)\n",
    "    _in_df = feature_trip_count(_in_df)\n",
    "\n",
    "    _in_df = _in_df\\\n",
    "        .withColumn(mean_travel, mean(dur_col).over(_w2)) \\\n",
    "        .withColumn(mean_cruise, mean(trip_cruise).over(_w2)) \\\n",
    "        .withColumn(mean_tip, mean(\"tip_amount\").over(_w2)) \\\n",
    "        .withColumn(month_income, sum(\"total_amount\").over(month_window)) \\\n",
    "        .withColumn(month_work_len  , sum(col(day_work_len)).over(month_window) / 60 / 60) \\\n",
    "        .withColumn(month_income_mean, (col(month_income) /  col(month_work_len)))\\\n",
    "        .withColumn(month_weekend, max(\"is_weekend\").over(month_window))\n",
    "    return _in_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for year in range(2009, 2020):\n",
    "    for month in range(1, 13):\n",
    "        if not os.path.exists(clean_file.format(year, month)):\n",
    "            continue\n",
    "        if check_file_exist(result_file.format(year, month)):\n",
    "            print(\"HAVE : {}-{}\".format(year, month))\n",
    "            continue\n",
    "        print(\"Start: {}-{}\".format(year, month))\n",
    "        print(\"[System]: Get cleaned parquet\")\n",
    "        cln = get_cln(year, month)\n",
    "        print(\"[System]: Feature duration\")\n",
    "        cln = filter_duration(cln)\n",
    "        print(\"[System]: Feature is weekend\")\n",
    "        cln = feature_is_weekend(cln)\n",
    "        print(\"[System]: Feature weather\")\n",
    "        cln = feature_weather(cln, year)\n",
    "\n",
    "        if not is_yellow:\n",
    "            cln = feature_foil(cln)\n",
    "\n",
    "        cln.write.mode(\"overwrite\").option(\"compression\", \"gzip\")\\\n",
    "            .partitionBy(\"pick_day\").parquet(result_dbfs.format(year, month))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}